{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0f25eb",
   "metadata": {},
   "source": [
    "### Module 2: Extracting , Cleaning and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9402b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Case Study\n",
    "\n",
    "You are provided with a file named “Brexit.docx”. This file contains the introductory \n",
    "paragraph from Wikipedia on Brexit. (https://en.wikipedia.org/wiki/Brexit) \n",
    "\n",
    "You have to perform some analysis on this paragraph by performing the following \n",
    "tasks: \n",
    "    \n",
    "1. Read the file “Brexit.docx” and write a function in Python named “GetNGrams” \n",
    "which takes a string and a number ‘n’ as input and returns n-grams from the string.\n",
    "Example: \n",
    "String: “John met with an accident”\n",
    "Output: \n",
    "When n=2 => [(John, met), (met, with), (with, an), (an, accident)]\n",
    "When n=3 => [(John, met, with), (met, with, an), (with, an, accident)]\n",
    "When n=4 => [(John, met, with, an), (met, with, an, accident)]\n",
    "\n",
    "2. Read the file “Brexit.docx” and write python functions which take a string as an \n",
    "input and returns:\n",
    "• Number of Nouns (all forms of noun). Take function name as “NounsCount”\n",
    "• Number of Pronouns (all forms). Take function name as “PronounsCount”\n",
    "• Number of Adjectives (all forms). Take function name as “AdjectivesCount”\n",
    "• Number of Verbs (all forms). Take function name as “VerbsCount”\n",
    "• Number of Adverbs (all forms). Take function name as “AdverbsCount”\n",
    "Plot a pie chart showing the distribution of nouns, pronouns, verbs, adverbs and \n",
    "adjectives. \n",
    "\n",
    "3. Read the file “Brexit.docx” and write python functions which take a string as an \n",
    "input and returns:\n",
    "• Number of geo-Political entities present in the file. Take function name as\n",
    "“GeoPoliticalCount”\n",
    "• Number of Persons present in the file. Take function name as “PersonsCount”\n",
    "• Numbers of Organizations mentioned in the file. Take function name as \n",
    "“OrganizationsCount”\n",
    "\n",
    "4. Answer the following questions:\n",
    "• Most frequent bi-gram from the data\n",
    "• Most frequent Noun\n",
    "• Most frequent GeoPolitical Entity\n",
    "• Most frequent person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c88167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Read the file “Brexit.docx” and write a function in Python named “GetNGrams” \n",
    "#which takes a string and a number ‘n’ as input and returns n-grams from the string.\n",
    "#Example: \n",
    "#String: “John met with an accident”\n",
    "#Output: \n",
    "#When n=2 => [(John, met), (met, with), (with, an), (an, accident)]\n",
    "#When n=3 => [(John, met, with), (met, with, an), (with, an, accident)]\n",
    "#When n=4 => [(John, met, with, an), (met, with, an, accident)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae11ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx \n",
    "\n",
    "Brexit = docx.Document('Brexit.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4347f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Brexit.paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ef3a0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "secondParagraph = Brexit.paragraphs[1].text\n",
    "sent_secondParagraph = sent_tokenize(secondParagraph)\n",
    "\n",
    "single_line =\"\"\n",
    "\n",
    "#len(Brexit.paragraphs)\n",
    "\n",
    "for i in range(0,len(Brexit.paragraphs)):\n",
    "    single_line += Brexit.paragraphs[i].text\n",
    "#sent_secondParagraph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ff420369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brexit\\xa0is the impending\\xa0\\xa0of the\\xa0\\xa0(UK) from the\\xa0\\xa0(EU). In a\\xa0, a majority of British voters supported leaving the EU. On 29 March 2017, the\\xa0 invoked\\xa0. The\\xa0\\xa0declares \"exit day\" to be 29 March 2019 at 11\\xa0p.m.\\xa0().Prime Minister\\xa0\\xa0announced the government\\'s intention not to seek permanent membership of the\\xa0\\xa0or the\\xa0\\xa0after leaving the EU and promised to\\xa0\\xa0the\\xa0\\xa0and incorporate existing\\xa0\\xa0into\\xa0.\\xa0A new government department, the\\xa0, was created in July 2016.\\xa0officially started in June 2017, aiming to complete the withdrawal agreement by October 2018. In June 2018, the UK and the EU published a joint progress report outlining agreement on issues including\\xa0,\\xa0\\xa0and\\xa0Euratom.The UK joined the\\xa0\\xa0(EC) in 1973, with membership confirmed by a\\xa0. In the 1970s and 1980s, withdrawal from the EC was advocated mainly by\\xa0Labour Party\\xa0members and\\xa0\\xa0figures. From the 1990s, the main advocates of withdrawal were the newly founded\\xa0\\xa0(UKIP) and an increasing number of Eurosceptic\\xa0\\xa0members. Prime Minister\\xa0\\xa0held the referendum in fulfilment of a 2015 manifesto pledge. Cameron, who had campaigned for \"Remain\", resigned after the referendum result and was succeeded by Theresa May, who called a\\xa0\\xa0less than a year later, in which she lost her overall majority. Her minority government is\\xa0\\xa0by the\\xa0.Six weeks after the referendum, the Bank of England introduced\\xa0\\xa0and lower interest rates, thus allowing both\\xa0\\xa0of\\xa0\\xa0and a rise in inflation that outpaced wage growth for most of 2017. The drop in the value of sterling has been claimed to have been caused in part by hedge-fund managers betting on Brexit against polls predicting a narrow victory for the \"Remain\" camp. There is a broad consensus in existing economic research that Brexit is likely to reduce the UK\\'s real\\xa0\\xa0in the medium term and long term. There is also agreement among economists that the Brexit referendum itself damaged the economy in the subsequent two years. Studies on effects that have materialised since the referendum show annual losses of £404 for the average UK household, and losses between 1.3% and 2.1% of UK GDP.\\xa0Brexit is likely to reduce immigration from\\xa0\\xa0(EEA) countries to the UK,\\xa0and poses challenges for UK higher education and academic research.\\xa0As of June 2018, the size of the \"\", the UK\\'s inheritance of existing EU trade agreements, and\\xa0\\xa0and other EU member states remain uncertain. The precise impact on the UK depends on whether the process will be a\\xa0.'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "e2e22846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'met'), ('met', 'with'), ('with', 'an'), ('an', 'accident')]\n",
      "[('John', 'met', 'with'), ('met', 'with', 'an'), ('with', 'an', 'accident')]\n",
      "[('John', 'met', 'with', 'an'), ('met', 'with', 'an', 'accident')]\n",
      "[('John',), ('met',), ('with',), ('an',), ('accident',)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import    bigrams, trigrams, ngrams\n",
    "\n",
    "def GetNGrams(txt,grams=2):\n",
    "    tokenized_txt = word_tokenize(txt)\n",
    "    return ngrams(tokenized_txt,grams)\n",
    "    \n",
    "    \n",
    "txt_str = \"John met with an accident\"\n",
    "print(list(GetNGrams(txt_str,2)))\n",
    "print(list(GetNGrams(txt_str,3)))\n",
    "print(list(GetNGrams(txt_str,4)))\n",
    "print(list(GetNGrams(txt_str,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816fbf41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "5faa5e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Read the file “Brexit.docx” and write python functions which take a string as an \n",
    "#input and returns:\n",
    "#• Number of Nouns (all forms of noun). Take function name as “NounsCount”\n",
    "#• Number of Pronouns (all forms). Take function name as “PronounsCount”\n",
    "#• Number of Adjectives (all forms). Take function name as “AdjectivesCount”\n",
    "#• Number of Verbs (all forms). Take function name as “VerbsCount”\n",
    "#• Number of Adverbs (all forms). Take function name as “AdverbsCount”\n",
    "#Plot a pie chart showing the distribution of nouns, pronouns, verbs, adverbs and \n",
    "#adjectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f73f5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def NounsCount(txt):\n",
    "    ncount = 0\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    #print(nltk.pos_tag(txt))\n",
    "    for i in word_tokens:\n",
    "        postag = nltk.pos_tag([i])[0][1]\n",
    "        if postag in ['NN','NNS','NNP','NNPS']:\n",
    "            ncount+=1\n",
    "        \n",
    "    return ncount\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "676fc558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PronounsCount(txt):\n",
    "    ncount = 0\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    for i in word_tokens:\n",
    "        postag = nltk.pos_tag([i])[0][1]\n",
    "        if postag in ['PRP','PRP$']:\n",
    "            ncount+=1\n",
    "        \n",
    "    return ncount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "517fd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdjectivesCount(txt):\n",
    "    ncount = 0\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    for i in word_tokens:\n",
    "        postag = nltk.pos_tag([i])[0][1]\n",
    "        if postag in ['JJ','JJR','JJS']:\n",
    "            ncount+=1\n",
    "        \n",
    "    return ncount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "58e26d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VerbsCount(txt):\n",
    "    ncount = 0\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    for i in word_tokens:\n",
    "        postag = nltk.pos_tag([i])[0][1]\n",
    "        if postag in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "            ncount+=1\n",
    "        \n",
    "    return ncount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bb1af7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdverbsCount(txt):\n",
    "    ncount = 0\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    for i in word_tokens:\n",
    "        postag = nltk.pos_tag([i])[0][1]\n",
    "        if postag in ['RB','RBR']:\n",
    "            ncount+=1\n",
    "        \n",
    "    return ncount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ddf93502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The UK joined the\\xa0\\xa0(EC) in 1973, with membership confirmed by a\\xa0. In the 1970s and 1980s, withdrawal from the EC was advocated mainly by\\xa0Labour Party\\xa0members and\\xa0\\xa0figures. From the 1990s, the main advocates of withdrawal were the newly founded\\xa0\\xa0(UKIP) and an increasing number of Eurosceptic\\xa0\\xa0members. Prime Minister\\xa0\\xa0held the referendum in fulfilment of a 2015 manifesto pledge. Cameron, who had campaigned for \"Remain\", resigned after the referendum result and was succeeded by Theresa May, who called a\\xa0\\xa0less than a year later, in which she lost her overall majority. Her minority government is\\xa0\\xa0by the\\xa0.'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_line=Brexit.paragraphs[3].text\n",
    "\n",
    "single_line\n",
    "\n",
    "#for i in  range( 0, len(Brexit.paragraphs)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0b86109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The UK joined the  (EC) in 1973, with membership confirmed by a . In the 1970s and 1980s, withdrawal from the EC was advocated mainly by Labour Party members and  figures. From the 1990s, the main advocates of withdrawal were the newly founded  (UKIP) and an increasing number of Eurosceptic  members. Prime Minister  held the referendum in fulfilment of a 2015 manifesto pledge. Cameron, who had campaigned for \"Remain\", resigned after the referendum result and was succeeded by Theresa May, who called a  less than a year later, in which she lost her overall majority. Her minority government is  by the .\n"
     ]
    }
   ],
   "source": [
    "print(single_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ff00894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_line2 = \"\"\"The UK joined the  (EC) in 1973, with membership confirmed by a . In the 1970s and 1980s, withdrawal from the EC was advocated mainly by Labour Party members and Cameron figured it. From the 1990s, the main advocates of withdrawal were the newly founded  (UKIP) and an increasing number of Eurosceptic  members. Prime Minister Theresa held the referendum in fulfilment of a 2015 manifesto pledge. Cameron, who had campaigned for \"Remain\", resigned after the referendum result and was succeeded by Theresa May, who called a  less than a year later, in which she lost her overall majority. Her minority government is  by the .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "03388185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NounsCount(single_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5b196ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PronounsCount(single_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "837452fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdjectivesCount(single_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fc6b7aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VerbsCount(single_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f77af94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdverbsCount(single_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Read the file “Brexit.docx” and write python functions which take a string as an \n",
    "#input and returns:\n",
    "#• Number of geo-Political entities present in the file. Take function name as\n",
    "#“GeoPoliticalCount”\n",
    "#• Number of Persons present in the file. Take function name as “PersonsCount”\n",
    "#• Numbers of Organizations mentioned in the file. Take function name as \n",
    "#“OrganizationsCount”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "18c6e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9d5ca952",
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_sent = \"The US President stays in the White House\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a34a9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeoPoliticalCount(txt):\n",
    "    ncount = 0\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    gpes = nltk.FreqDist()\n",
    "    \n",
    "    for i in nltk.ne_chunk(nltk.pos_tag(word_tokens)):\n",
    "        if hasattr(i, 'label') and i.label()=='GPE':\n",
    "            #print(i)\n",
    "            gpe = i[0][0] \n",
    "            gpes[gpe]+=1\n",
    "    \n",
    "    #print(list(orgs))\n",
    "    return len(gpes.keys())\n",
    "\n",
    "def PersonsCount(txt):\n",
    "    ncount = 0\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    persons = nltk.FreqDist()\n",
    "    \n",
    "    for i in nltk.ne_chunk(nltk.pos_tag(word_tokens)):\n",
    "        if hasattr(i, 'label') and i.label()=='PERSON':\n",
    "            \n",
    "            person = i[0][0] \n",
    "            persons[person]+=1\n",
    "            #print(' '.join(c[0] for c in i))\n",
    "    #print(list(persons))\n",
    "    return len(persons.keys())\n",
    "\n",
    "def OrganizationsCount(txt):\n",
    "    ncount = 0\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    orgs = nltk.FreqDist()\n",
    "    \n",
    "    for i in nltk.ne_chunk(nltk.pos_tag(word_tokens)):\n",
    "        if hasattr(i, 'label') and i.label()=='ORGANIZATION':\n",
    "            #print(i)\n",
    "            org = i[0][0] \n",
    "            orgs[org]+=1\n",
    "    \n",
    "    #print(list(orgs))\n",
    "    return len(orgs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "bbadf8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeoPoliticalCount(single_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "bbffe2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PersonsCount(single_line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "daa0542e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrganizationsCount(single_line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f6ce9f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION US/NNP)\n",
      "  President/NNP\n",
      "  stays/VBZ\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (FACILITY White/NNP House/NNP))\n"
     ]
    }
   ],
   "source": [
    "NE_NER = ne_chunk(NE_tags)\n",
    "print(NE_NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "cd7cbf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PersonsCount(samsung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6087abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung =\"\"\"Are foldable phones and tablets cool again? That'll be up to Samsung, LG, TCL and the other device makers. \n",
    "\n",
    "But after seeing the Samsung Flex Hybrid, which folds and slides, this week at CES 2023, I'm starting to once again feel excited about the cutting-edge tech that has yet to catch on in a serious way. While the concept model remained in the hands of a Samsung staffer, seeing it for myself renewed my hope in the possibilities we have yet to explore with screens that can fold, bend, slide and roll.\n",
    "\n",
    "Read more: Check out our CES 2023 live blog, must-see reveals, most futuristic tech and wackiest gadgets.\n",
    "\n",
    "As someone who has used a number of these early devices from Samsung, Motorola, Oppo and others, I'll admit to being a bit disillusioned with the appeal of foldables in recent years. The Flex Hybrid and other prototypes from Samsung's Display division may have changed that. \n",
    "\n",
    "There were slideables, foldables and even some devices that used multiple technologies, and any of them could show up in the not-too-distant future. The Flex Hybrid is a foldable tablet that has an additional display that pulls out, with the demo giving an example of watching a football game on the full tablet screen before pulling out the additional display real estate to see stats and other information. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "198c7d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PersonsCount(samsung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ba771594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrganizationsCount(samsung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f33ab153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Answer the following questions:\n",
    "#• Most frequent bi-gram from the data\n",
    "#• Most frequent Noun\n",
    "#• Most frequent GeoPolitical Entity\n",
    "#• Most frequent person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011d32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "6e36cd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent bigram is  (',', 'the')\n"
     ]
    }
   ],
   "source": [
    "#• Most frequent bi-gram from the data\n",
    "\n",
    "bigram_fdist = nltk.FreqDist()\n",
    "\n",
    "for i in list(GetNGrams(single_line,2)):\n",
    "    bigram_fdist[i]+=1\n",
    "\n",
    "print(\"The most frequent bigram is \",bigram_fdist.most_common(1)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "c2f97b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent non is: [('UK', 10)]\n"
     ]
    }
   ],
   "source": [
    "#• Most frequent Noun\n",
    "\n",
    "NounsCount(single_line)\n",
    "noun_fdist = nltk.FreqDist()\n",
    "\n",
    "word_tokens = word_tokenize(single_line)\n",
    "for i in word_tokens:\n",
    "    postag = nltk.pos_tag([i])[0][1]\n",
    "    if postag in ['NN','NNS','NNP','NNPS']:\n",
    "        noun_fdist[i]+=1\n",
    "\n",
    "print(\"The most frequent non is:\",noun_fdist.most_common(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "97bec6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EU', 6)]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#• Most frequent GeoPolitical Entity\n",
    "\n",
    "word_tokens = word_tokenize(single_line)\n",
    "gpes = nltk.FreqDist()\n",
    "\n",
    "for i in nltk.ne_chunk(nltk.pos_tag(word_tokens)):\n",
    "    if hasattr(i, 'label') and i.label()=='GPE':\n",
    "        gpe = i[0][0] \n",
    "        gpes[gpe]+=1\n",
    "\n",
    "gpes.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "def5f687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brexit', 2)]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#• Most frequent person\n",
    "\n",
    "word_tokens = word_tokenize(single_line)\n",
    "persons = nltk.FreqDist()\n",
    "\n",
    "for i in nltk.ne_chunk(nltk.pos_tag(word_tokens)):\n",
    "    if hasattr(i, 'label') and i.label()=='PERSON':\n",
    "        person = i[0][0] \n",
    "        persons[person]+=1\n",
    "\n",
    "persons.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024d1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
